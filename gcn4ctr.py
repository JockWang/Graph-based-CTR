# -*- coding: utf-8 -*-
"""GCNCTR_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11W5XPdu63sr5G7RVwG-gVkPZ0OrLgY8N
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install --verbose --no-cache-dir torch-scatter
!pip install --verbose --no-cache-dir torch-sparse
!pip install --verbose --no-cache-dir torch-cluster
!pip install --verbose --no-cache-dir torch-spline-conv
!pip install torch-geometric

# 数据预处理
!python /content/drive/My\ Drive/Colab\ Notebooks/graph/preprocess_1.py -d book

# !cat /usr/local/cuda/version.txt
import torch
import torch.nn as nn
from torch_geometric.data import InMemoryDataset, Data
from torch_geometric.nn import GCNConv
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import logging

LOG_FORMAT = "%(asctime)s - %(levelname)s - %(message)s"
DATE_FORMAT = "%m/%d/%Y %H:%M:%S"
logging.basicConfig(level=logging.DEBUG, format=LOG_FORMAT, datefmt=DATE_FORMAT)

NUMBER = {
    'book':{
        'u': 17860,
        'i': 14967,
        'a': 77903,
    }
}

def getGraph():
  df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/graph/data/'+DATASET+'/graph.txt', header=None, index_col=None)
  logging.info('Generating subgraph...')
  head_index, tail_index= [], []
  for value in df.values:
    head_index.append(value[0])
    tail_index.append(value[-1])
  edge_index = torch.tensor([head_index, tail_index], dtype=torch.long)
  x = torch.tensor(range(NUMBER[DATASET]['i']), dtype=torch.long)
  logging.info('Done.')
  return Data(x=x, edge_index=edge_index)

def getGraph2():
  df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/graph/data/'+DATASET+'/kg_final.txt', sep='\t', header=None, index_col=None)
  logging.info('Generating subgraph...')
  head_index, tail_index = [], []
  for value in df.values:
    head_index.append(value[0])
    tail_index.append(value[-1])
  edge_index = torch.tensor([head_index, tail_index], dtype=torch.long)
  x = torch.tensor(range(NUMBER[DATASET]['a']), dtype=torch.long)
  logging.info('Done.')
  return Data(x=x, edge_index=edge_index)

class Graph(InMemoryDataset):
  def __init__(self, root, transform=None, pre_transform=None):
    super(Graph, self).__init__(root, transform, pre_transform)
    self.data, self.slices = torch.load(self.processed_paths[0])
  
  @property
  def raw_file_names(self):
    return []
  
  @property
  def processed_file_names(self):
    return ['/content/drive/My Drive/Colab Notebooks/graph/data/'+DATASET+'/'+DATASET+'.graph']
  
  def download(self):
    pass
  
  def process(self):
    graph = []
    df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/graph/data/'+DATASET+'/kg_final.txt', sep='\t', header=None, index_col=None)
    logging.info('Generating subgraph...')
    for i in range(NUMBER[DATASET]['i']):
      head_index, tail_index, x_index = [], [], []
      if i not in x_index:
        x_index.append(i)
      for value in df.values:
        if i == value[0] or i == value[1]:
          head_index.append(value[0])
          tail_index.append(value[-1])
          if value[0] not in x_index:
            x_index.append(value[0])
          if value[1] not in x_index:
            x_index.append(value[1])
      edge_index = torch.tensor([head_index, tail_index], dtype=torch.long)
      x = torch.tensor(x_index, dtype=torch.long)
      graph.append(Data(x=x, edge_index=edge_index))
    
    data, slices = self.collate(graph)
    torch.save((data, slices), self.processed_paths[0])
    logging.info('Done.')

class MyDataset(Dataset):
  def __init__(self, mode='train', dataset='book'):
    super(MyDataset, self).__init__()
    df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/graph/data/'+dataset+'/ratings_final.txt', sep='\t', header=None, index_col=None).values
    train, test = train_test_split(df, test_size=0.2, random_state=2019)
    if mode == 'train':
      self.data = train
    else:
      self.data = test
    logging.info(mode+' set size:'+str(self.data.shape[0]))

  def __getitem__(self, index):
    temp = self.data[index]
    user, item, label = torch.tensor(temp[0], dtype=torch.long), torch.tensor(temp[1], dtype=torch.long), torch.tensor([temp[2]], dtype=torch.float)
    return user, item, label

  def __len__(self):
    return len(self.data)

class Model(nn.Module):
  def __init__(self, user_hidden_size, item_hidden_size, u_nodes, i_nodes):
    super(Model, self).__init__()
    self.user_hidden_size, self.u_nodes = user_hidden_size, u_nodes
    self.item_hidden_size, self.i_nodes = item_hidden_size, i_nodes
    self.user_embedding = nn.Embedding(self.u_nodes, self.user_hidden_size)
    self.item_embedding = nn.Embedding(self.i_nodes, self.item_hidden_size)
    self.conv1 = GCNConv(self.item_hidden_size, 100)
    self.conv2 = GCNConv(100, 16)
    self.fc1 = nn.Linear(80, 8)
    self.fc2 = nn.Linear(8, 1)
    self.sig = nn.Sigmoid()
  
  def forward(self, u, i, graph):
    u_embedding = self.user_embedding(u)
    i_embedding = self.item_embedding(graph.x)
    i_embedding = self.conv1(i_embedding, graph.edge_index)
    i_embedding = self.conv2(i_embedding, graph.edge_index)
    i_embedding = i_embedding[i]
    u_i = torch.cat((u_embedding, i_embedding), 1)
    out = self.fc1(u_i)
    out = self.fc2(out)

    return self.sig(out)

DATASET = 'book'
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
logging.info('Use device:'+str(device))

graph = getGraph2().to(device)
print(graph)
train_loader = DataLoader(MyDataset(mode='train'), batch_size=64, shuffle=True)
test_loader = DataLoader(MyDataset(mode='test'), batch_size=64, shuffle=False)

model = Model(64, 512, NUMBER[DATASET]['u'], NUMBER[DATASET]['a']).to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)
criterion = nn.BCELoss()
logging.info(model)

epochs = 30
for epoch in tqdm(range(epochs)):
  running_loss = 0
  for k, [user, item, label] in enumerate(train_loader):
    u, i, l = user.to(device), item.to(device), label.to(device)

    optimizer.zero_grad()

    out = model(u, i, graph)
    loss = criterion(out, l)
    loss.backward()
    optimizer.step()

    running_loss += loss.item()
    if k % 100 == 99:
      logging.info('Epoch:%d Step:%d loss:%.5f' % (epoch + 1, k+1, running_loss / 100))
      running_loss = 0

y, y_ = [], []
for k, [user, item, label] in enumerate(test_loader):
  u, i, l = user.to(device), item.to(device), label

  y += label.tolist()[0]
  out = model(u, i, graph)
  y_ += out.tolist()[0]
  # print(y_)
  if k % 100 == 99:
    logging.info('Step: %d AUC: %.6f' % (k+1,roc_auc_score(y, y_)))

logging.info('Final AUC: %.6f' % roc_auc_score(y, y_))

# 01/11/2020 09:32:18 - INFO - Step: 100 AUC: 0.783795
# 01/11/2020 09:32:21 - INFO - Step: 200 AUC: 0.697778
# 01/11/2020 09:32:23 - INFO - Step: 300 AUC: 0.726779
# 01/11/2020 09:32:25 - INFO - Step: 400 AUC: 0.716967
# 01/11/2020 09:32:25 - INFO - Final AUC: 0.712125

